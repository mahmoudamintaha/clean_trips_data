{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from fuzzywuzzy import process\n",
    "import os\n",
    "\n",
    "## Read all the sheets of the input workbook\n",
    "dfs = pd.read_excel(\"E:\\myport\\input\\MyPoert AUG sheet1.xlsx\", sheet_name=None)\n",
    "\n",
    "\n",
    "# Remove excessive columns.\n",
    "# Unify the column names. \n",
    "# Add a country column using the dictinary key of (dfs).\n",
    "for key, value in dfs.items():\n",
    "    dfs[key]= dfs[key].iloc[:, 0:3]\n",
    "    dfs[key].columns = ['trip', 'price_offer', 'country']\n",
    "    dfs[key]['country'] = str(key)\n",
    "\n",
    "\n",
    "\n",
    "# ADD all sheets into one dataframe\n",
    "all_dfs = list(dfs.values())\n",
    "full_data = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Read backend files which will validate the main file manipulation\n",
    "countries = pd.read_excel('E:\\myport\\input\\Countries IDs.xlsx')\n",
    "ports = pd.read_excel('E:\\myport\\input\\Ports_ceties_codes_and_IDs.xlsx')\n",
    "\n",
    "full_data['price_offer2'] = full_data['price_offer'].shift(-1)\n",
    "full_data['price_offer3'] = full_data['price_offer'].shift(-2)\n",
    "full_data = full_data [ full_data ['trip'].notnull()]\n",
    "full_data0 = full_data\n",
    "\n",
    "# Extract departure port, arrival port, trip type, And price\n",
    "def extract_from_to_trip_type(row):\n",
    "    \"\"\"\n",
    "    Extracts the departure and destination of the trip from 'trip' column,\n",
    "    Price and trip_type from 'price_offer' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setting the initial values of cells.\n",
    "    trip = row['trip']\n",
    "    price_offer = row['price_offer']\n",
    "    price_offer2 = row['price_offer2']\n",
    "    price_offer3 = row['price_offer3']\n",
    "    \n",
    "    # Extracting the departure and destination ports from the trip column using regex\n",
    "    search = re.findall(r'(?:FRM|From|from|FROM)(?:\\s*)(.*?)(?:\\s*to|TO|To)(?:\\s*)(.*?)\\s*$', trip)\n",
    "    if search:\n",
    "        full_from, full_to = search[0]\n",
    "    else:\n",
    "        full_from, full_to = None, None\n",
    "\n",
    "    # Extracting trip_type from price_offer column\n",
    "    trip_type_match = re.search(r'(?:Trip|TRIP|trip)(?:\\s?)(?::)(?:\\s?)(\\w)', price_offer)\n",
    "    trip_type = trip_type_match.group(1).upper() if trip_type_match else None\n",
    "\n",
    "    # Extracting price from price_offer column\n",
    "    price_match = re.search(r'(\\d+)', price_offer)\n",
    "    if price_match:\n",
    "        price = price_match.group(1)\n",
    "    else:\n",
    "        price_match = re.search(r'(\\d+)', price_offer2)\n",
    "        if price_match:\n",
    "            price = price_match.group(1)\n",
    "        else:\n",
    "            price_match = re.search(r'(\\d+)', price_offer3)\n",
    "            price = price_match.group(1)\n",
    "\n",
    "    return pd.Series({'full_from': full_from, 'full_to': full_to, 'trip_type': trip_type, 'price_raw': price})\n",
    "\n",
    "# Append the extracted values to the data frame\n",
    "full_data[['full_from', 'full_to', 'trip_type', 'price_raw']] = full_data.apply(extract_from_to_trip_type, axis=1)\n",
    "full_data1 = full_data\n",
    "\n",
    "# create a column containing a price dictionary that also includes Arabic script \n",
    "def ar_num(row):\n",
    "    p_raw = row['price_raw']\n",
    "    \n",
    "    ar_num = '۰١٢٣٤٥٦٧٨٩'\n",
    "    en_num = '0123456789'\n",
    "\n",
    "    translator = str.maketrans(en_num, ar_num)\n",
    "    p_ar = p_raw.translate(translator)\n",
    "\n",
    "    return '{' + f'\"en\":\"{p_raw}\",\"ar\":\"{p_ar}\",\"gr\":\"{p_raw}\",\"it\":\"{p_raw}\",\"cz\":\"{p_raw}\",\"fr\":\"{p_raw}\",\"sk\":\"{p_raw}\"' + '}'\n",
    "\n",
    "full_data['price'] = full_data.apply(ar_num, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Drop unneded columns \n",
    "full_data.drop(['trip', 'price_offer', 'price_offer2', 'price_offer3', 'price_raw'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Read a global country/capital CSV to compensate entries with capital mentioned instead of country\n",
    "country_capital = pd.read_csv('https://raw.githubusercontent.com/icyrockcom/country-capitals/master/data/country-list.csv', usecols=[\"country\", \"capital\"])\n",
    "\n",
    "# Merge the manipulated data with our countries file from backend\n",
    "# Then merge again with capital from github file.\n",
    "full_data = full_data.merge(countries, how='left', left_on='country', right_on='Country')\n",
    "full_data = full_data.merge(country_capital, how='left', left_on='country', right_on='capital')\n",
    "full_data.fillna('', inplace=True)\n",
    "full_data2 = full_data\n",
    "\n",
    "\n",
    "# Create a column named corrected_country with the right country name for a better merge with the file from the backend.\n",
    "def country_correction(row):\n",
    "    country1 = row['Country']\n",
    "    country2 = row['country_y']\n",
    "\n",
    "    if country1 == '':\n",
    "        corrected_country = country2\n",
    "    else:\n",
    "        corrected_country = country1\n",
    "\n",
    "    return corrected_country\n",
    "\n",
    "full_data['corrected_country'] = full_data.apply(country_correction, axis=1)\n",
    "full_data3 = full_data\n",
    "\n",
    "# Drop unneded columns\n",
    "full_data = full_data.drop([\"country_x\", \"ID\", \"Country\", \"country_y\", \"capital\"], axis=1)\n",
    "full_data = full_data.merge(countries, how='left', left_on='corrected_country', right_on='Country')\n",
    "full_data4 = full_data\n",
    "\n",
    "# Add publish_date and expire_date columns\n",
    "# Create the 'publish_date' column with a fixed value\n",
    "full_data['publish_date'] = '04-04-2024'\n",
    "\n",
    "# Convert the 'publish_date' column to datetime format\n",
    "full_data['publish_date'] = pd.to_datetime(full_data['publish_date'], format='%d-%m-%Y')\n",
    "\n",
    "# Calculate the 'expire_date' by adding 33 days to the 'publish_date'\n",
    "full_data['expire_date'] = full_data['publish_date'] + pd.Timedelta(days=33)\n",
    "\n",
    "# Convert date columns to string so that excel doesn't convert them into timestamps\n",
    "full_data['publish_date'] = full_data['publish_date'].astype(str)\n",
    "full_data['expire_date'] = full_data['expire_date'].astype(str)\n",
    "\n",
    "# Make the extracted columns in lower case for better matching\n",
    "for col in full_data.columns[0:2]:\n",
    "    full_data[col] = full_data[col].str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Using fuzzy matching create two columns based on the best match\n",
    "# between our extracted ports and port names in the back end, To get rid of misspelling problem\n",
    "def find_best_match(value, choices, threshold=70):\n",
    "    match = process.extractOne(value, choices, score_cutoff=threshold)\n",
    "    return match[0] if match else None  # Return the first element if match is not None, otherwise return None\n",
    "\n",
    "\n",
    "full_data['best_from'] = full_data['full_from'].apply(lambda x: find_best_match(x, ports['Port Name']))\n",
    "full_data['best_to'] = full_data['full_to'].apply(lambda x: find_best_match(x, ports['Port Name']))\n",
    "full_data5 = full_data\n",
    "\n",
    "# make the following columns in lower case for better merging\n",
    "ports['City'] = ports['City'].str.lower()\n",
    "ports['Port Name'] = ports['Port Name'].str.lower()\n",
    "full_data['best_from'] = full_data['best_from'].str.lower()\n",
    "full_data['best_to'] = full_data['best_to'].str.lower()\n",
    "\n",
    "# Check for ports doesn't exist in backend \n",
    "wrong_departure =  full_data5[(full_data5['best_from'].isnull()) \\\n",
    "                              & ~(full_data5['full_from'].isin(ports['Port Name'])) \\\n",
    "                                & ~(full_data5['full_from'].isin(ports['City']))]['full_from'].unique()\n",
    "wrong_arrival = full_data5[(full_data5['best_to'].isnull()) \\\n",
    "                           & ~(full_data5['full_to'].isin(ports['Port Name'])) \\\n",
    "                            & ~(full_data5['full_to'].isin(ports['City']))]['full_to'].unique()\n",
    "\n",
    "wrong_ports_dep = full_data[full_data['full_from'].isin(wrong_departure)]\n",
    "wrong_ports_arr =  full_data[full_data['full_to'].isin(wrong_arrival)]\n",
    "\n",
    "wrong_ports_dep['Error Type'] = 'Wrong departure port'\n",
    "wrong_ports_arr['Error Type'] = 'Wrong arrival port'\n",
    "\n",
    "wrong_ports_dep = wrong_ports_dep[['corrected_country', 'full_from', 'full_to', 'trip_type',  'Error Type']]\n",
    "wrong_ports_arr = wrong_ports_arr[['corrected_country', 'full_from', 'full_to', 'trip_type',  'Error Type']]\n",
    "\n",
    "# Check for countries the doesn't exist in backend\n",
    "wrong_country = full_data1[full_data1['country'].isin(full_data2[full_data2['corrected_country'] == '']['country_x'].unique())]\n",
    "wrong_country['Error Type'] = 'Wrong Country name'\n",
    "wrong_country = wrong_country[['country', 'full_from', 'full_to', 'trip_type', 'Error Type']]\n",
    "\n",
    "# Correct trips that entered city name instead of port name in the departure port\n",
    "dep_cor1 = full_data.merge(ports, left_on='best_from', right_on = 'Port Name')\n",
    "dep_cor2 = full_data.merge(ports, left_on='full_from', right_on ='City')\n",
    "full_data = pd.concat([dep_cor1, dep_cor2], ignore_index=True)\n",
    "\n",
    "# Correct trips that entered city name instead of port name in the arrival port\n",
    "arr_cor1 = full_data.merge(ports, left_on='best_to', right_on = 'Port Name')\n",
    "arr_cor2 = full_data.merge(ports, left_on='full_to', right_on ='City')\n",
    "full_data = pd.concat([arr_cor1, arr_cor2], ignore_index=True)\n",
    "\n",
    "# Extract and correct column names to the desired names \n",
    "full_data.columns\n",
    "full_data.columns = ['full_from', 'full_to', 'trip_type', 'price', 'corrected_country',\n",
    "       'Country', 'country_id', 'publish_date', 'expire_date', 'best_from',\n",
    "       'best_to', 'City_from', 'Port_name_from', 'Port_code_from', 'port_from', 'City_to',\n",
    "       'Port_name_to', 'Port_code_to', 'port_to']\n",
    "\n",
    "# Create the url column \n",
    "full_data['url'] = full_data['Port_code_from'].str.lower() + '-' + full_data['Port_code_to'].str.lower() + '-' + full_data['trip_type'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Delete cities that contains more than one port but mentioned in our data as a port which will cause confusion\n",
    "grouped_cities = ports.groupby('City', ).count().iloc[:, 0]\n",
    "cities_count = grouped_cities[grouped_cities > 1].index\n",
    "unique_cities_departure = dep_cor2['City'].unique()\n",
    "unique_cities_arrival = arr_cor2['City_y'].unique()\n",
    "cities_with_multiple_ports_departue = [x for x in unique_cities_departure if x in   cities_count]\n",
    "cities_with_multiple_ports_arrival = [x for x in unique_cities_arrival if x in   cities_count]\n",
    "\n",
    "full_data = full_data[~full_data['full_from'].isin(cities_with_multiple_ports_departue)]\n",
    "full_data = full_data[~full_data['full_to'].isin(cities_with_multiple_ports_arrival)]\n",
    "\n",
    "# Delete trips with wrong country names\n",
    "full_data = full_data[full_data['corrected_country'] != '']\n",
    "\n",
    "\n",
    "# CREATE THE OUTPUT DATAFRAMES \n",
    "offers_template = full_data[['port_from', 'port_to', 'trip_type', 'url', 'publish_date', 'expire_date']]\n",
    "offers_template = offers_template.drop_duplicates()\n",
    "offer_contents = full_data[['url','country_id', 'price']]\n",
    "\n",
    "\n",
    "# Save the output xlsx files\n",
    "try:\n",
    "    offers_template.to_excel('offers_template.xlsx', index=False)\n",
    "    offer_contents.to_excel('offer_contents.xlsx', index=False)\n",
    "except PermissionError:\n",
    "    print('Remove old Output files')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Trips with misspelled departure port or city instead of port\n",
    "trips_with_misspelled_departure = full_data[full_data['best_from'] != full_data['full_from']][['full_from','Port_name_from', 'full_to', 'trip_type', 'Country']]\n",
    "trips_with_misspelled_departure.columns = ['extracted_departure_port','correct_departue_port', 'extracted_arrival_port', 'trip_type', 'Country']\n",
    "trips_with_misspelled_departure['Error Type'] = 'Misspelled departure port'\n",
    "trips_with_misspelled_departure = trips_with_misspelled_departure[['Country', 'extracted_departure_port', 'extracted_arrival_port', 'trip_type',  'Error Type']]\n",
    "\n",
    "\n",
    "# Trips with misspelled arrival port or city instead of port\n",
    "trips_with_misspelled_arrive = full_data[full_data['best_to'] != full_data['full_to']][['full_from', 'full_to','Port_name_to', 'trip_type', 'Country']]\n",
    "trips_with_misspelled_arrive.columns = ['extracted_departure_port', 'extracted_arrival_port','correct_arrival_port', 'trip_type', 'Country']\n",
    "trips_with_misspelled_arrive['Error Type'] = 'Misspelled arrival port'\n",
    "trips_with_misspelled_arrive = trips_with_misspelled_arrive[['Country', 'extracted_departure_port', 'extracted_arrival_port', 'trip_type',  'Error Type']]\n",
    "\n",
    "\n",
    "\n",
    "report_dfs = [wrong_country, wrong_ports_dep, wrong_ports_arr, trips_with_misspelled_departure, trips_with_misspelled_arrive]\n",
    "for df in report_dfs:\n",
    "    df.columns = ['country', 'full_from', 'full_to', 'trip_type', 'Error Type']\n",
    "pd.concat(report_dfs).to_excel('report.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
